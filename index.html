<!DOCTYPE HTML>
<!--
	Dimension by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Akther Tech</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<style>
			.list-item a {
				display: none;
			}

			.list-item:hover a {
				display: inline;
			}
		</style>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="logo">
							<span class="icon fa-gem"></span>
						</div>
						<div class="content">
							<div class="inner">
								<h1>Shekh Akther</h1>
								<p>Big Data Professional with Software Engineering background.</p>
								<p>| Certified Amazon Web Services Solutions Architect Associate | Certified Java Developer | </p>
							</div>
						</div>
						<nav>
							<ul>
								<li><a href="#intro">Intro</a></li>
								<li><a href="#work">Work</a></li>
								<li><a href="#pipeline">UseCases</a></li>
								<li><a href="https://www.linkedin.com/in/shekh-akther/">LinkedIn</a></li>
								<li><a href="mailto:shekh@akthertraders.nl">Contact</a></li>
								<!--<li><a href="#contact">Contact</a></li>-->
								<!--<li><a href="#elements">Elements</a></li>-->
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Intro -->
							<article id="intro">
								<h2 class="major">Intro</h2>
								<span class="image main"><img src="images/pic01-profile.jpg" alt="" /></span>
<!--								<p>I am Shekh Morshed Akther, Big Data professional with Software Engineering background. </p>-->

								<p>
									<span style="white-space: pre-line">
										I am Data Engineer having a background as Software engineering with more than 16 years of Industry experience.

										Technology is a tool to drive our vision, make our life better. More we are using technology we are generating more data.
										To get more insights, values from high volume of data I found much interest working as Big Data professional as following:

											* Design Solution architecture for Data driven services
											* Implement realtime streaming and batch processing big data services
											* Bring Software engineering best practices in Data engineering
											* Productionizing and monitoring (automated) data pipelines and micro services
											* IAAS: Use terraform to build, change and version infrastructure cloud resources
											* Optimized cost for running cloud services

										I help customers to onboard on Cloud, build data pipeline platform, implement business requirements from PoC to production
									</span>
								</p>


								<p>
									<span style="white-space: pre-line">
										Please check out our presentation <a href="https://www.slideshare.net/databricks/monitoring-half-a-million-ml-models-iot-streaming-data-and-automated-quality-check-on-delta-lake">for Data + AI Summit Europe 2020</a>.
										Our presentation in video <a href="https://www.youtube.com/watch?v=3dOePPkwEJc">Monitoring Half a Million ML Models, IoT Streaming Data, and Automated Quality Check on Delta Lake</a>
									</span>	
								</p>
								
								</p>
							</article>

						<!-- Work -->
							<article id="work">
								<h2 class="major">Work</h2>
								<span class="image main"><img src="images/de.gif" width="90%" height="auto" alt="" /></span>
								<p>
									<span style="white-space: pre-line">
										Senior Data Engineer Consultant
										ING Nederland
										Aug 2021 - Present
										Responsibilities:
											- Embrace Cloud technology so that Business can focus on their core purpose.
											- Take part evaluating right tools for business need.
											- From brainstorming, PoC to put data ingestion streaming pipelines to production.
											- Take part in requirement analysis, architecture design decision and hands on implementation.
											- Work with collaboration with Google
										Tech stack: Google Cloud Platform (IAM, VPC, Artifact Registry, Cloud Monitoring, Compute Engine,GCS, PubSub, Dataflow, BigQuery). Azure DevOps, Azure KeyVault, Kafka
									</span>

									<span style="white-space: pre-line">
										Senior Software Engineer / Data Engineer
										Eneco/Quby
										Jan 2019 - Jul 2021
										Responsibilities:
											- Design, develop, maintain (build it and run it) real-time streaming and batch processing jobs and services, data pipelines following Kappa and Lambda architecture.
											- Manage highly scalable (peta-bytes scale) multi-tenant data lakes and data processing infrastructure.
											- IAAS: Use terraform to build, change and version infrastructure cloud resources
										Tech stack: AWS (IAM, VPC, S3, SQS, SNS, Kinesis Data Streams, Beanstalk, API Gateway, Cloudwatch, DynamoDB), Databricks Notebook, Apache Spark
									</span>

									<span style="white-space: pre-line">
										Java Developer
										Quby
										Mar 2016 - Dec 2018
										Working as a backend developer at Quby (later merged with Eneco), the company behind Toon
										that makes your home smart.Toon provides you insight into your energy consumption,
										control your heating, lighting, smoke detectorsand smart plugs on the go.
										Toon also provides you insight of you Solar energy production.

										Using Toon App, you can control your energy appliance from anywhere. You can even program your thermostat andschedule holiday mode temperatures.
										Responsibilities:
											- Develop new features based on business requirements.
											- Containerized backend services and horizontal scalable.
											- Develop new features based on business requirements.
											- Expose Toon API for 3rd party integration.
											- Implemented several backend services for user onboarding, providing information and notification.
											- Write automated tests for regression and load test
											- Implemented CI/CD deployment pipelines
											- Use Mesos/Marathon for container orchestration
											- Organize/participate hackathon(s)
									</span>

									<span style="white-space: pre-line">
										Software Engineer Consultant
										Cimsolutions B.V.
										Feb 2012 - Feb 2016

										Client: Nederlandse Spoorwegen (NS)
										Software Engineer
										Jul 2014 - Feb 2016
										OV-Chipkaart (OVCP) is one of the core business module of NSR. On an average, more than 1million people travel by train daily.
										As number of transactions are increasing, complexities in different business modules are also increasing.
										As a result,NS would like to redesign and implement its Back-office system using an Enterprise Service Bus
										which will result in cost savings and will improve flexibility and scalability.
										Responsibilities:
											- Requirement Analysis, design and develop proof of concepts
											- Develop components using Java EE 6 and integrate using Enterprise Service Bus
											- As a team, we deliver from PoC to Production of backoffice system

										Client: Vanderlande
										Test Automation Engineer
										Sep 2013 - May 2014
										Vanderlande is a global company that specializes in automated material handling systems,
										including conveyor belts, for various industries such as airports, warehouses, and distribution centers.
										Worked as a TAE for conveyor belts functional automation.

										Client: Nederlandse Spoorwegen (NS)
										Software Engineer
										Jun 2013 - Aug 2013
										Implemented backend of "NS Groepsticket" functionality

										Client: Netherlands Aerospace Centre (NLR)
										Software Engineer
										Jul 2012 - Jan 2013
										Worked on MVCNS Aircraft Noice detection simulation backend development

									</span>

									<span style="white-space: pre-line">
										Senior Software Engineer
										Grameen Solutions
										Oct 2009 - Dec 2011
									</span>

									<span style="white-space: pre-line">
										Software Engineer
										Domain Technologies
										2006 - 2009
									</span>
								</p>
							</article>

						<!-- Use-cases -->
						<article id="pipeline">
							<h2 class="major">How to build scalable pipeline</h2>
							<span class="image main"><img src="images/analytics_pipeline.png" alt="" width="90%" /></span>

							<p>
								<span style="white-space: pre-line">
								To create a scalable analytics pipeline in Google Cloud Platform (GCP), you can leverage various services and tools available.
								Here is a high-level overview of the steps involved in building a scalable analytics pipeline in GCP:

								<strong>Data Ingestion/Capture</strong>: Begin by ingesting data from various sources into GCP. You can use services like Cloud Storage, Pub/Sub, or Data Transfer Service to bring data from on-premises systems, external sources, or other cloud providers into GCP.

								<strong> Data Processing</strong>: Once the data is ingested, you need to process it to extract insights. GCP offers several options for data processing, such as:

								- Cloud Dataflow: A fully managed service for real-time and batch data processing. Dataflow can handle large-scale data transformations and supports multiple programming languages.

								- Dataproc: A managed Apache Hadoop and Spark service. You can use it for distributed processing of large datasets with tools like Apache Spark or Apache Flink.

								- BigQuery: A serverless data warehouse and analytics platform that supports running SQL queries on large datasets. BigQuery can directly process structured and semi-structured data, making it suitable for analysis and aggregation tasks.

								<strong> Data Storage</strong>: Store the processed data in appropriate storage solutions based on your requirements:

								- BigQuery: Store structured and semi-structured data in BigQuery tables for further analysis.

								- Cloud Storage: Use Cloud Storage for storing raw or processed data in object format. It provides durability, scalability, and accessibility to other GCP services.

								- Firestore, Cloud Spanner, or Cloud Bigtable: These are other database options you can consider based on your specific needs.

								<strong> Data Analysis</strong>: Analyze the stored data to gain insights and build reports or visualizations. You can use the following tools for data analysis in GCP:

								- BigQuery: Perform complex analytics and run SQL queries directly on BigQuery tables.

								- Data Studio: Create interactive dashboards and reports using a drag-and-drop interface. Connect Data Studio with BigQuery or other data sources.

								- Looker: A comprehensive business intelligence platform for data exploration and visualization. Looker integrates with BigQuery and other data sources to provide powerful analytics capabilities.

								<strong> Data Visualization and Reporting</strong>: Visualize your analysis results and generate reports for decision-making purposes. GCP offers various tools for data visualization, including:

								- Data Studio: Create customized, interactive dashboards and reports using data from BigQuery or other supported data sources.

								- Looker: Build comprehensive visualizations and reports using Looker's intuitive interface.

								Finally, <strong>Monitoring and Optimization</strong> : Continuously monitor and optimize your analytics pipeline for performance and cost-efficiency.
								Use GCP tools like Cloud Monitoring, Cloud Logging, and Cloud Trace to monitor your pipeline components and identify bottlenecks or issues.

								Please note that building a scalable analytics pipeline is an iterative process. You may need to refine and enhance your pipeline based on changing requirements, data volumes, or analytical needs.
								</span>
							</p>
						</article>

						<!-- About -->
							<article id="about">
								<h2 class="major">About</h2>
								<span class="image main"><img src="images/pic03.jpg" alt="" /></span>
								<p>Lorem ipsum dolor sit amet, consectetur et adipiscing elit. Praesent eleifend dignissim arcu, at eleifend sapien imperdiet ac. Aliquam erat volutpat. Praesent urna nisi, fringila lorem et vehicula lacinia quam. Integer sollicitudin mauris nec lorem luctus ultrices. Aliquam libero et malesuada fames ac ante ipsum primis in faucibus. Cras viverra ligula sit amet ex mollis mattis lorem ipsum dolor sit amet.</p>
							</article>


						<!-- Elements -->
							<article id="elements">
								<h2 class="major">Elements</h2>

								<section>
									<h3 class="major">Text</h3>
									<p>This is <b>bold</b> and this is <strong>strong</strong>. This is <i>italic</i> and this is <em>emphasized</em>.
									This is <sup>superscript</sup> text and this is <sub>subscript</sub> text.
									This is <u>underlined</u> and this is code: <code>for (;;) { ... }</code>. Finally, <a href="#">this is a link</a>.</p>
									<hr />
									<h2>Heading Level 2</h2>
									<h3>Heading Level 3</h3>
									<h4>Heading Level 4</h4>
									<h5>Heading Level 5</h5>
									<h6>Heading Level 6</h6>
									<hr />
									<h4>Blockquote</h4>
									<blockquote>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan faucibus. Vestibulum ante ipsum primis in faucibus lorem ipsum dolor sit amet nullam adipiscing eu felis.</blockquote>
									<h4>Preformatted</h4>
									<pre><code>i = 0;

while (!deck.isInOrder()) {
    print 'Iteration ' + i;
    deck.shuffle();
    i++;
}

print 'It took ' + i + ' iterations to sort the deck.';</code></pre>
								</section>

								<section>
									<h3 class="major">Lists</h3>

									<h4>Unordered</h4>
									<ul>
										<li>Dolor pulvinar etiam.</li>
										<li>Sagittis adipiscing.</li>
										<li>Felis enim feugiat.</li>
									</ul>

									<h4>Alternate</h4>
									<ul class="alt">
										<li>Dolor pulvinar etiam.</li>
										<li>Sagittis adipiscing.</li>
										<li>Felis enim feugiat.</li>
									</ul>

									<h4>Ordered</h4>
									<ol>
										<li>Dolor pulvinar etiam.</li>
										<li>Etiam vel felis viverra.</li>
										<li>Felis enim feugiat.</li>
										<li>Dolor pulvinar etiam.</li>
										<li>Etiam vel felis lorem.</li>
										<li>Felis enim et feugiat.</li>
									</ol>
									<h4>Icons</h4>
									<ul class="icons">
										<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
									</ul>

									<h4>Actions</h4>
									<ul class="actions">
										<li><a href="#" class="button primary">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
									<ul class="actions stacked">
										<li><a href="#" class="button primary">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
								</section>



							</article>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; Akther Traders.</p>
					</footer>

			</div>

		<!-- BG -->
			<div id="bg"></div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
